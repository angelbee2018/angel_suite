script_description <- "# THREE-FRAME TRANSLATION ######
Attempts to translate the nucleotides of all transcripts flanking all the splice junctions given.
Uses PARALLEL PURRR (FURRR) ^___^ is much faster than the last version
Recommended CPU/RAM connsumption: 12-16 cores/60GB for ~30,000 junctions. 4-8 cores/32GB for ~4000 junctions. 2-4 cores/16GB for ~1000 junctions. 
I personally would not use more than 16 cores because you get diminishing returns due to the longer time it takes to delegate the tasks to each worker.
RAM usage  scales by the number of cores you use. I do not recommend going lower than 16GB."

# print the arguments received by the R script
cat("Arguments input:", commandArgs(), sep = "\n")
args = 
  commandArgs(trailingOnly = TRUE)
cat(args)
cat("number of arguments specified:", length(args))

# SET ENVIRONMENT ##########
#if (!requireNamespace("BiocManager", quietly = TRUE))
#install.packages("BiocManager")
#BiocManager::install(c("seqinr", "tidyverse", "purrr", "dplyr", "rtracklayer", "data.table", "furrr", "RhpcBLASctl", "optparse"))

library(seqinr)
library(tidyverse)
library(furrr)
library(rtracklayer)
library(data.table)
library(optparse)
library(future.callr)

library(tictoc)
# start counting execution time of the whole script
tictoc::tic("Overall execution time")

source("/mnt/LTS/tools/angel_suite/source/main_source.R")

# manage arguments
list_input_arg_info = list(
  "1" = make_option(c("-J", "--junction_table_path"), type = "character", default = NULL, 
                    help = "Compulsory. path to table containing junctions of interest. for example, UNION_junc_coor type files (JUM only). MUST contain columns start, end, chr, strand, and splicemode. OPTIONAL colnames: gene_name, organism, custom_identifier. one row per junction.", metavar = "character"),
  "2" = make_option(c("-I", "--intron_retention_string"), type = "character", default = "intron_retention", 
                    help = "Compulsory. A regular expression which matches to all characters in the splicemode column which are associated with IR events.", metavar = "character"),
  "3" = make_option(c("-S", "--source_tag"), type = "character", default = "three_frame_translation_junctions", 
                    help = "Compulsory. A character string that will be added to the FASTA headers to indicate the source. It is in the same position as \"sp\" for UniProt fasta files.", metavar = "character"),
  "4" = make_option(c("-G", "--reconstructed_gtf_path"), type = "character", default = NULL, 
                    help = "Compulsory. path to the actual reconstructed GTF file (e.g. from Cufflinks, Strawberry). NOT THE CONTAINING DIRECTORY. tip: for better junction matching, combine the reconstructed GTF with reference GTF beforehand e.g. using StringTie", metavar = "character"),
  "5" = make_option(c("-R", "--reference_genome_fasta_dir"), type = "character", default = NULL, 
                    help = "Compulsory. path to the directory containing the genome FASTA files. Ideally from Ensembl... you need separate files by chromosomes, NOT the primary assembly. 
              FORMATTING IMPORTANT!!!! MAKE SURE THE REF. GENOME FASTA FILES ARE IN THE FORMAT: <_anything_><chr>.fa e.g. \"Homo_sapiens.GRCh38.dna.chromosome.MT.fa\" OR \"chr16.fa\" OR \"Y.fa\". What will not work: anything which does not have .fa extension e.g. \"chr16.fasta\", anything between the chromosome number and the .fa extension e.g. \"chromosome1.ensembl.fa\"", metavar = "character"),
  "6" = make_option(c("-U", "--upstream_window_size"), type = "double", default = 50,
                    help = "Optional. how many nucleotides to translate upstream W.R.T. the middle of the exon for junction-based mode, the total nt. length to be translated will be arg3 + arg4. default for both is 50.", metavar = "double"),
  "7" = make_option(c("-D", "--downstream_window_size"), type = "double", default = 50,
                    help = "Optional. how many nt to translate downstream W.R.T. the transcript. for exon-based mode, both will be 50 by default. instead, the window size is taken as the MINIMUM required length to be considered for translation starting from the middle of the exon.", metavar = "double"),
  "8" = make_option(c("-T", "--output_name"), type = "character", default = NULL,
                    help = "Compulsory. a character string of what the final FASTA database file name and output table will be called. a.k.a. what do you want to save the FASTA as? IMPORTANT: MUST BE A STRING WITHOUT THE EXTENSION AND NOT A DIRECTORY. THE .txt EXTENSION WILL AUTOMATICALLY BE ADDED FOR THE OUTPUT FILE. e.g. correct: custom_database incorrect: custom_database.fasta incorrect: custom_database/", metavar = "character"),
  "9" = make_option(c("-O", "--output_dir"), type = "character", default = NULL, 
                    help = "Compulsory. output directory. where do you want to save the custom databases? IMPORTANT: directory must end in a \"/\". e.g. correct: ~/outputdir/ incorrect: ~/outputdir", metavar = "character"),
  "10" = make_option(c("-C", "--ncores"), type = "character", default = 0, 
                     help = "Optional. Number of cores to use. possible inputs: numbers 1 to any integer. By default, uses all cores (ncores = 0). If a single number is specified, it will just tell future to loop thru chromosomes in parallel using the specified core count. If numberxnumberxnumber for example 7x4x2 then 28x2 = 56 cores will be used. 7 for chromosomes and 4 for inside each chromosome and 2 for each element further inside.", metavar = "character"),
  "11" = make_option(c("-H", "--chrmode"), type = "integer", default = 0, 
                     help = "Optional. Specifies which chromosomes to do: select what chromosomes you want translated. possible inputs: numbers 0-2. 0 (default): nuclear chromosomes only i,e, 1:22, X & Y. 1: nuclear + mitochondrial i.e. 1:22, X & Y, M. 2: everything including haplotype/fusion chromosomes etc... this is possible provided the chromosome names.", metavar = "integer"),
  "12" = make_option(c("-N", "--nonchrname"), type = "character", default = NULL, 
                     help = "Compulsory only if you have specified \"--chrmode 2\". nonchromosomal file name. if you are doing haplotypes, please specify what the reference genome FASTA file for it is called or the script won't know. This single FASTA file must contain all the haplotype information. The script won't try to search for a second file. In ensembl, this file is called \"Homo_sapiens.GRCh38.dna.nonchromosomal.fa\" or more generally, \"*nonchromosomal.fa\". So for this option, you would specify \"--nonchrname nonchromosomal\".", metavar = "character"),
  "13" = make_option(c("-V", "--save_workspace_when_done"), type = "character", default = FALSE,
                     help = "Turn this on if you want to save the R workspace in the same name as the --output_name. YES: saves at the end. DEBUG: saves at each critical step. NO: doesn't save.", metavar = "character"),
  "14" = make_option(c("-P", "--tempdir"), type = "character", default = NULL,
                     help = "Compulsory. Specify a temporary directory.", metavar = "character")
)

input_arg_info <- OptionParser(option_list = list_input_arg_info, description = script_description)
input_args <- input_arg_info %>% parse_args

# check if the input arguments are O.K
if ((list(input_args$junction_table_path, input_args$reconstructed_gtf_path, input_args$reference_genome_fasta_dir, input_args$output_name, input_args$output_dir) %>% lapply(is.null) %>% unlist %>% any == TRUE) | 
    (input_args$chrmode == 2 & is.null(input_args$nonchrname) == TRUE)) {
  
  print_help(input_arg_info)
  
  stop("Make sure you entered the arguments correctly", call. = FALSE)
  
}

junction_table_path <- input_args$junction_table_path
intron_retention_string <- input_args$intron_retention_string
source_tag <- input_args$source_tag
reconstructed_gtf_path <- input_args$reconstructed_gtf_path
reference_genome_fasta_dir <- input_args$reference_genome_fasta_dir
upstream_window_size <- input_args$upstream_window_size
downstream_window_size <- input_args$downstream_window_size
output_name <- input_args$output_name
output_dir <- input_args$output_dir
ncores <- input_args$ncores
chrmode <- input_args$chrmode
nonchrname <- input_args$nonchrname
save_workspace_when_done <- input_args$save_workspace_when_done
tempdir <- input_args$tempdir

# DEBUG ########
# tibble_JUM_diff_table <- read.delim("/mnt/Tertiary/sharedfolder/PGNEXUS_kassem_MSC/Kassem_OB/analysis_JUM/run_2_PGNEXUS_OBseries_readlength100/R_processing_results/wide_table_of_7855_constitutive_VSRs_dPSI_OB_diff_qvalue0.01_dPSI0.15_no_na.txt", sep = "\t", stringsAsFactors = FALSE, check.names = FALSE) %>% as_tibble
# # strsplit into a chr start end strand tibble
# list_constituent_junctions <- tibble_JUM_diff_table[, c("Gene", "splicemode", "chr", "start", "end", "strand")] %>% 
#   array_tree %>%
#   # strsplit the chr, strand, start and end, and leave the rest alone.
#   purrr::map(.f = function(a1) {
#     
#     # DEBUG ###
#     # a1 <- tibble_JUM_diff_table[, c("Gene", "splicemode", "chr", "start", "end", "strand")] %>% 
#       # array_tree %>%
#       # .[[1]]
#     ###########
#     
#     # strsplit the chr, start, end, strand elements.
#     tibble_split_chr_start_end_strand <- a1[c("chr", "start", "end", "strand")] %>% 
#       purrr::map(~strsplit(.x, split = ";") %>% unlist)
#     
#     # combine the gene and splicemode elements, tibblise and return
#     purrr::splice(a1[c("Gene", "splicemode")],
#                   tibble_split_chr_start_end_strand) %>%
#       as_tibble %>% 
#       return
#   })
# 
# # rbind and tibblise
# tibble_constituent_junctions <- list_constituent_junctions %>% rbindlist(use.names = TRUE) %>% as_tibble
# 
# tibble_junction_table <- tibble_constituent_junctions %>% 
#   dplyr::rename("gene_name" = "Gene") %>%
#   add_column("source" = "JUM_strawberry",
#              "organism" = "Homo sapiens",
#              "custom_identifier" = NA)
# 

junction_table_path <- "/mnt/LTS/projects/2020_RNA_atlas/results/R_processing_results_PSISigma/atlas_polya_psisigma_VSR_junctions_export_for_3FT.txt"
intron_retention_string <- "IR"
reconstructed_gtf_path <- "/mnt/LTS/projects/2020_RNA_atlas/results/analysis_strawberry_polya/atlas_polya_ensembl_stringtiemerged.gtf"
source_tag <- "atlas_polya_psisigma_VSR_junctions_recon_ensembl"
reference_genome_fasta_dir <- "/mnt/LTS/reference_data/hg38_ensembl_reference/raw_genome_fasta/dna_by_chr/"
upstream_window_size <- 50
downstream_window_size <- 50
output_name <- "atlas_polya_psisigma_VSR_junctions_recon_ensembl_3FT"
output_dir <- "/mnt/LTS/projects/2020_RNA_atlas/results/results_proteome_validation/"
ncores <- "96x10x16"
chrmode <- 1
nonchrname <- NULL
save_workspace_when_done <- "NO"
tempdir <- "/mnt/LTS/projects/2020_RNA_atlas/results/results_proteome_validation/temp/"

##################################

cat("junction_table_path:", junction_table_path, "\n")
cat("intron_retention_string:", intron_retention_string, "\n")
cat("source_tag:", source_tag, "\n")
cat("reconstructed_gtf_path:", reconstructed_gtf_path, "\n")
cat("reference_genome_fasta_dir:", reference_genome_fasta_dir, "\n")
cat("upstream_window_size:", upstream_window_size, "\n")
cat("downstream_window_size:", downstream_window_size, "\n")
cat("output_name:", output_name, "\n")
cat("output_dir:", output_dir, "\n")
cat("ncores:", ncores, "\n")
cat("chrmode:", chrmode, "\n")
cat("nonchrname:", nonchrname, "\n")
cat("save_workspace_when_done:", save_workspace_when_done, "\n")
cat("tempdir:", tempdir, "\n")

if(!dir.exists(output_dir) ) {
  dir.create(output_dir, recursive = TRUE)}

if(!dir.exists(tempdir) ) {
  dir.create(tempdir, recursive = TRUE)}

# Open a file to send messages to
# message_divert_path <- file(paste(output_dir, "/", output_name, "_messages.txt", sep = ""), open = "wt")
# Divert messages to that file
# sink(message_divert_path, type = "message")

# manage parrallellisation rrlllRll

options(future.globals.maxSize = 30000000000, future.fork.enable = TRUE)

max_number_of_cores <- parallel::detectCores()

if (grepl(x = ncores, pattern = "x") == FALSE) {
  
  if (ncores != 0) {
    number_of_workers <- ncores
    cat(future::availableCores(), "cores will be used\n")
  } else {
    number_of_workers <- future::availableCores()
    cat(future::availableCores(), "cores will be used\n")
  } 
  
} else if (grepl(x = ncores, pattern = "x") == TRUE) {
  
  ncores_level_1 <- ncores %>% strsplit(split = "x") %>% unlist %>% .[1] %>% type.convert(as.is = TRUE)
  ncores_level_2 <- ncores %>% strsplit(split = "x") %>% unlist %>% .[2] %>% type.convert(as.is = TRUE)
  ncores_level_3 <- ncores %>% strsplit(split = "x") %>% unlist %>% .[3] %>% type.convert(as.is = TRUE)
  
  plan(list(tweak(multicore, workers = ncores_level_1, gc = TRUE), 
            tweak(multicore, workers = ncores_level_2, gc = TRUE),
            tweak(multicore, workers = ncores_level_3, gc = TRUE))
  )
  
  cat((ncores %>% strsplit(split = "x") %>% unlist %>% .[1] %>% type.convert(as.is = TRUE)) * (ncores %>% strsplit(split = "x") %>% unlist %>% .[2] %>% type.convert(as.is = TRUE)) * (ncores %>% strsplit(split = "x") %>% unlist %>% .[3] %>% type.convert(as.is = TRUE)), "cores will be used in total\n")
  cat("first layer:", ncores_level_1, "cores\n")
  cat("second layer:", ncores_level_2, "cores\n")
  cat("third layer:", ncores_level_3, "cores\n")
  
}

# set layered parallelisation in furrr

# if ((number_of_workers - length(vector_chr_in_common)) %/% number_of_workers > 1) {
#   plan(list(tweak(multicore, workers = min(number_of_workers, length(vector_chr_in_common))), 
#             tweak(multicore, workers = (number_of_workers - length(vector_chr_in_common)) %/% number_of_workers))
# )
# } else {
#   plan(multicore, workers = number_of_workers)
# }

# activate the below if linux R starts acting up

# if(Sys.info()["sysname"] == "Windows") {
#   
#   cat("number of workers:", number_of_workers, "\n")
#   
#   future::plan(multicore)
#   options(future.globals.maxSize = 30000000000, mc.cores = input_args$ncores)
#   
# } else {
#   
#   cat("number of workers:", number_of_workers, "\n")
#   
#   future::plan(multisession, workers = number_of_workers)
#   # library(RhpcBLASctl)
#   # RhpcBLASctl::omp_set_num_threads(number_of_workers)
#   # RhpcBLASctl::blas_set_num_threads(number_of_workers)
#   options(future.globals.maxSize = 30000000000, mc.cores = number_of_workers)
#   
# }

# specify the chromosomes to be run, according to user option --chrmode
if (chrmode == 1) {
  
  # all nuclear chromosomes + mitochondria
  chr_to_run <- c(1:22, "X", "Y", "MT")
  
} else if (chrmode == 2) {
  
  chr_to_run <- c(1:22, "X", "Y", "MT", nonchrname)
  
} else {
  
  # if the user put in a stupid number then we'll assume they just want all the nuclear chromosomes.
  chr_to_run <- c(1:22, "X", "Y")
  
}

# DEFINE FUNCTIONS ##########################

# FUNCTION TO 3 FRAME TRANSLATE ONE LIST CONTAINING NUCLEOTIDE SEQUENCE AND STRAND

nt.sequence_strand_threeframetranslate <- function(vector_forward_nucleotides, strand) {
  
  if (strand == "+") {
    
    translation_result <- list("translation_frame_0" = seqinr::translate(vector_forward_nucleotides, frame = 0, sens = "F"),
                               "translation_frame_1" = seqinr::translate(vector_forward_nucleotides, frame = 1, sens = "F"),
                               "translation_frame_2" = seqinr::translate(vector_forward_nucleotides, frame = 2, sens = "F"))
    
  } else if (strand == "-") {
    
    translation_result <- list("translation_frame_0" = seqinr::translate(vector_forward_nucleotides, frame = 0, sens = "R"),
                               "translation_frame_1" = seqinr::translate(vector_forward_nucleotides, frame = 1, sens = "R"),
                               "translation_frame_2" = seqinr::translate(vector_forward_nucleotides, frame = 2, sens = "R"))
    
  }
  
  return(translation_result)
  
}

# END nt.sequence_strand_threeframetranslate

# FUNCTION TO EXTRACT TRANSCRIPTS WITH JUNCTION-FLANKING EXONS.
# NOTE: to be used with purrr
# input: spliceregion_list: a list containing details of ONE junction: $diff_exon_chr, $diff_exon_start, $diff_exon_end
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
extract_junction.flanking.exons <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, tolerance_left = 1, tolerance_right = 1, tolerance_inside = 1, tolerance_outside = 0, match_consecutive = TRUE, return_type = "exon") {
  
  # DEBUG ###################
  
  # query_chr = a1$chr %>% type.convert
  # query_start = a1$event_region_start %>% type.convert
  # query_end = a1$event_region_end %>% type.convert
  # query_strand = "*"
  # tibble_gtf_table = tibble_ref_gtf
  # tolerance_left = 0
  # tolerance_right = 0
  # tolerance_inside = 0
  # tolerance_outside = 0
  # match_consecutive = FALSE
  # return_type = "exon"
  
  ###########################
  
  # print(paste("now processing junction number", index))
  
  if (!query_strand %in% c("+", "-")) {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$start <= ((query_end %>% as.numeric) + 1 + tolerance_outside + tolerance_left) & .$end >= ((query_start %>% as.numeric) - 1 - tolerance_outside - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% as.numeric) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% as.numeric) + tolerance_inside + tolerance_left)), ] %>% .[.$type %in% return_type, ]
    
  } else if (query_strand == "+" | query_strand == "-") {
    
    tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$strand == query_strand %>% trimws, ] %>% .[.$start <= ((query_end %>% as.numeric) + 1 + tolerance_right) & .$end >= ((query_start %>% as.numeric) - 1 - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% as.numeric) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% as.numeric) + tolerance_inside + tolerance_left)), ] %>% .[.$type %in% return_type, ]
    
  } else {
    
    stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
    
  }
  
  list_of_junction_associated_transcripts <- tibble_gtf_subset_flanking_exons$transcript_id %>% unique %>% array_tree %>% flatten
  
  # make a list for each transcript that directly flanks a junction.
  # then filter so that there are only a) exon PAIRS which b) are directly connected in the mature (spliced) transcript
  
  if (match_consecutive == TRUE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2) %>% keep(.x = ., .p = ~abs((.x[2, "exon_number"] %>% paste %>% as.numeric) - (.x[1, "exon_number"] %>% paste %>% as.numeric)) == 1)
    
  } else if (match_consecutive == FALSE) {
    
    list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% as.numeric)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2)
    
  }
  
  # for those consecutive exons which were found to flank a junction, get all the entries of the parent transcript
  list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_tibbles_flanking_exon_gtf.entries_per_transcript, .f = ~list(
    
    "matched_flanking_exons" = .x, 
    "parent_transcript" = tibble_gtf_table[tibble_gtf_table$transcript_id == .x$transcript_id %>% unique %>% paste, ] %>% .[-which(is.na(.$exon_number)), ] %>%
      dplyr::arrange(exon_number %>% as.numeric)))
  
  return(list_of_tibbles_flanking_exon_gtf.entries_per_transcript)
  
}

# END extract_junction.flanking.exons_JUM() ###

# FUNCTION to calculate where the exon's amino acid sequence will be within a whole stretch of translated transcript
# which is the ceiling of the distance /3 - translation frame + 1. reverse for reverse strand.
calculate_translation_frame_relative_start_end_position <- function(ES, EE, TL, strand, frame) {
  # ES: exon start (transcript-relative nucleotide position), EE: exon end, TL: transcript length, frame: 0-2
  
  if (strand == "+") {
    
    exon_start_AA_position <- ceiling((ES - 1 - frame) / 3) + 1
    exon_end_AA_position <- floor((EE - 1 - frame) / 3)
    
  } else if (strand == "-") {
    
    exon_start_AA_position <- ceiling((TL - EE - frame) / 3) + 1
    exon_end_AA_position <- floor((TL - ES - frame) / 3)
    
  }
  
  return(list("exon_start_AA_position" = exon_start_AA_position, "exon_end_AA_position" = exon_end_AA_position))
  
}

# FUNCTIONS to test if the left/right side of stop codons in an exon are translatable or not. (i.e. whether uORF or dORF exists or not)
## NOTE: by definition, the first AA of the uORF is the first nucleotide in the window.
find_valid_uORF <- function(list) {
  
  AA_sequence <- list[[1]] %>% unlist
  window_start_AA_position <- list[[2]] %>% paste %>% as.numeric
  window_end_AA_position <- list[[3]] %>% paste %>% as.numeric
  junction_AA_position <- list[[4]] %>% paste %>% as.numeric 
  
  validity_test <- stringr::str_detect(AA_sequence[1:(window_start_AA_position - 1)] %>% rev %>% paste(collapse = ""), "^[^\\*]+M|^[^\\*]+$")
  
  exonic_uORF_sequence <- AA_sequence[window_start_AA_position:window_end_AA_position] %>% paste(collapse = "") %>% strsplit(., split = "\\*") %>% unlist %>% first
  
  # if there is indeed a valid uORF then translate the first part within the exon
  if (validity_test == TRUE & nchar(exonic_uORF_sequence) > (junction_AA_position - window_start_AA_position + 1)) {
    
    return(exonic_uORF_sequence)
    
  } else {
    
    return("NONE_VALID")
    
  }
  
}

## NOTE: by definition, the first AA of the dORF is the last nucleotide in the window - dORF AA length + 1!!
find_valid_dORF <- function(list) {
  
  AA_sequence <- list[[1]] %>% unlist
  window_start_AA_position <- list[[2]] %>% paste %>% as.numeric
  window_end_AA_position <- list[[3]] %>% paste %>% as.numeric
  junction_AA_position <- list[[4]] %>% paste %>% as.numeric 
  
  validity_test <- stringr::str_detect(AA_sequence[window_start_AA_position:window_end_AA_position] %>% rev %>% paste(collapse = ""), "^[^\\*]+M|^[^\\*]+$")
  
  exonic_dORF_sequence <- AA_sequence[window_start_AA_position:window_end_AA_position] %>% paste(collapse = "") %>% strsplit(., split = "\\*") %>% unlist %>% last
  
  # if there is indeed a valid dORF then translate the first part within the exon
  if (validity_test == TRUE & nchar(exonic_dORF_sequence) > (junction_AA_position - window_start_AA_position + 1)) {
    
    return(exonic_dORF_sequence)
    
  } else {
    
    return("NONE_VALID")
    
  }
  
}

# END find_valid_uORF() and find_valid_dORF()

# MAIN FUNCTION TO DO 3FT OF JUNCTIONS
# Behaviour: for each junction, look up every single transcript that it's associated with. Translate in three frames and find which frame can validly translate the exon.
# These transcripts are matched according to both reference and reconstructed GTF.
# The smallest protein in humans is 44 AA so the smallest valid translatable nucleotide length is 132 nt. 
# Translated region included in the upstream/downstream window must cross the splice junction.

# END FUNCTIONS #####################################################################################################
#####################################################################################################################
#####################################################################################################################

cat("# BEGIN EXECUTION #################################\n")

vector_ref_genome_paths_by_chr <- paste(reference_genome_fasta_dir, list.files(reference_genome_fasta_dir)[list.files(reference_genome_fasta_dir) %>% grep(., pattern = ".*.fa$")], sep = "")

# reference_genome_fasta <- seqinr::read.fasta(file = reference_genome_fasta_path, forceDNAtolower = FALSE)

# total_peptide_window_size <- upstream_window_size + downstream_window_size
# cat("total translation window size:", total_peptide_window_size, "\n")

tibble_recon_gtf <- rtracklayer::import(reconstructed_gtf_path) %>% as_tibble %>% dplyr::mutate_if(is.factor, as.character) %>% type_convert
# list-ify the recon GTF by chromosome
list_recon_gtf_subset_by_chr <- tibble_recon_gtf %>% dplyr::group_split(seqnames)

names(list_recon_gtf_subset_by_chr) <- list_recon_gtf_subset_by_chr %>% purrr::map(.f = ~.x$seqnames %>% unique) %>% unlist

# filter chr for only user specified chr
list_recon_gtf_subset_by_chr <- list_recon_gtf_subset_by_chr[chr_to_run]

cat("GTF importing done\n")

tibble_junction_table <- read.delim(junction_table_path, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE) %>% as_tibble %>% unique
# %>% .[sample(1:nrow(.), size = 100),]
# list-ify the junction table by chromosome
list_junction_table_by_chr <- tibble_junction_table %>% dplyr::group_split(chr)

# filter chr for only user specified chr
names(list_junction_table_by_chr) <- list_junction_table_by_chr %>% purrr::map(~.$chr %>% unique) %>% unlist

# subset the recon GTF and junction table by chromosomes in common so that we can map2 over them
vector_chr_in_common <- intersect(names(list_recon_gtf_subset_by_chr), names(list_junction_table_by_chr))

list_junction_table_by_chr <- list_junction_table_by_chr[vector_chr_in_common]
list_recon_gtf_subset_by_chr <- list_recon_gtf_subset_by_chr[vector_chr_in_common]

cat("get positions of the vector where the path of the ref. genome fasta\n")
vector_ref_genome_paths_by_chr_position <- vector_chr_in_common %>% purrr::map(.f = function(a1) {
  
  # DEBUG ###
  # a1 <- 1
  ###########
  
  # cat(a1, "\n")
  
  ref_genome_path_by_chr_position <- grep(x = vector_ref_genome_paths_by_chr, pattern = paste("(\\D|^)", a1, ".fa$", sep = ""))
  
  if (length(ref_genome_path_by_chr_position) != 1) {
    
    stop("Something is wrong with the contents of the fasta file directory. Please check that it's structured in the desired format.")
    
  } else {
    
    return(ref_genome_path_by_chr_position)
    
  }
  
} ) %>% unlist

# fetch full path of ref. genome fasta
vector_ref_genome_fasta_path <- paste(vector_ref_genome_paths_by_chr[vector_ref_genome_paths_by_chr_position])

plan(list(tweak(multicore, workers = ncores_level_1),
          tweak(multicore, workers = ncores_level_2)))

number_of_entries_per_chunk <- 200

# further split each chromosome list into smaller sectors to reduce parallel overhead. we do this by chunking across the genome.
list_junction_table_sectored0 <- furrr::future_map(
  .x = list_junction_table_by_chr,
  .f = function(a1) {
    
    # DEBUG ###
    # a1 <- list_junction_table_by_chr[[1]]
    ###########
    
    tibble_alt_exons <- a1 %>% dplyr::arrange(start)
    
    # get the maximum coordinate range of each row
    tibble_coord_range_of_each_row <- tibble(
      "min" = purrr::map(.x = tibble_alt_exons[, c("start", "end")] %>% purrr::array_tree(), .f = ~min(.x %>% unlist %>% type.convert)) %>% unlist,
      "max" = purrr::map(.x = tibble_alt_exons[, c("start", "end")] %>% purrr::array_tree(), .f = ~max(.x %>% unlist %>% type.convert)) %>% unlist
    )
    
    # group into islands using a 0 flag
    tibble_coords_flag_table <- dplyr::bind_rows(
      tibble("coord" = tibble_coord_range_of_each_row$min, "flag" = 1),
      tibble("coord" = tibble_coord_range_of_each_row$max, "flag" = -1)
    ) %>% dplyr::arrange(`coord`)
    
    vec_cumulative_sum <- tibble_coords_flag_table$flag %>% purrr::accumulate(sum, .dir = "forward")
    
    tibble_island_intervals <- purrr::map2(
      # starts
      .x = tibble_coords_flag_table[which(vec_cumulative_sum == 1 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 0), ] %>% .$coord,
      # ends
      .y = tibble_coords_flag_table[which(vec_cumulative_sum == 0 & c(0, vec_cumulative_sum[1:(length(vec_cumulative_sum) - 1)]) == 1), ] %>% .$coord,
      .f = ~tibble("chr" = tibble_alt_exons$chr %>% unique, "start" = .x, "end" = .y, "strand" = tibble_alt_exons$strand %>% unique)
    ) %>% rbindlist(fill = TRUE, use.names = TRUE) %>% as_tibble
    
    # join islands to prevent having too many list elements and having the same transcript appear many many times in the split GTF
    list_islands_joined_sectored <- purrr::map(
      .x = split(x = 1:nrow(tibble_island_intervals), f = ceiling(seq_along(1:nrow(tibble_island_intervals))/number_of_entries_per_chunk)),
      .f = ~tibble_island_intervals[.x, ])
    ## new, amalgamated intervals
    tibble_island_intervals <- list_islands_joined_sectored %>% purrr::map(~tibble("chr" = .x$chr %>% unique %>% .[1], "start" = .x$start %>% .[1], "end" = .x$end %>% .[nrow(.x)], "strand" = .x$strand %>% unique %>% .[1])) %>% 
      data.table::rbindlist() %>%
      tibble::as_tibble()
    
    L1_list_junction_table_sectored <- purrr::map(
      .x = tibble_island_intervals %>% purrr::array_tree(),
      .f = function(b1) {
        
        tibble_alt_exons[which(tibble_coord_range_of_each_row$min >= (b1$start %>% type.convert) & tibble_coord_range_of_each_row$max <= (b1$end %>% type.convert)), ] %>% 
          return
        
      } )
    
    return(
      list(
        "L1_list_junction_table_sectored" = L1_list_junction_table_sectored,
        "tibble_island_intervals" = tibble_island_intervals
      )
    )
    
  }, .progress = TRUE )

list_junction_table_sectored <- purrr::map(.x = list_junction_table_sectored0, .f = ~.x$L1_list_junction_table_sectored) %>% purrr::flatten()
list_island_intervals <- purrr::map(.x = list_junction_table_sectored0, .f = ~.x$tibble_island_intervals)

# split the recon GTF now
list_recon_gtf_sectored0 <- furrr::future_map2(
  .x = list_island_intervals,
  .y = list_recon_gtf_subset_by_chr,
  .f = function(a1, a2) {
    
    # DEBUG ###
    # a1 <- list_island_intervals[[1]]
    # a2 <- list_recon_gtf_subset_by_chr[[1]]
    ###########
    
    L1_list_island_intervals <- a1 %>% purrr::array_tree()
    
    # we now proceed to get all GTF transcripts which overlap with the intervals
    L1_list_recon_gtf_sectored <- purrr::map(
      .x = L1_list_island_intervals,
      .f = function(b1) {
        
        tibble_overlappiing_transcripts <- a2[a2$type == "transcript", ] %>% .[.$start <= (b1$end %>% type.convert(as.is = TRUE)) & .$end >= (b1$start %>% type.convert(as.is = TRUE)), ]
        
        tibble_overlapping_transcript_features <- dplyr::bind_rows(tibble_overlappiing_transcripts, a2[a2$transcript_id %in% tibble_overlappiing_transcripts$transcript_id, ])
        
        return(tibble_overlapping_transcript_features)
        
      } )
    
    return(L1_list_recon_gtf_sectored)
    
  }, .progress = TRUE )

list_recon_gtf_sectored <- list_recon_gtf_sectored0 %>% purrr::flatten()

print("Number of GTF entries safely omitted:")
print((list_recon_gtf_sectored %>% purrr::map(~.x %>% nrow) %>% unlist %>% sum) - nrow(tibble_recon_gtf))

plan(list(tweak(multicore, workers = ncores_level_1),
          tweak(multicore, workers = ncores_level_2),
          tweak(multicore, workers = ncores_level_3)))

cat("match VSRs to reconstructed transcriptome + 3FT\n")

# a1 <- list_junction_table_sectored %>% .[setdiff(1:length(list_junction_table_sectored), list.files(paste(tempdir, sep = ""), pattern = paste(output_name, "_list_3FT_result_temp_.*.Rlist", sep = "")) %>% gsub(pattern = ".*_temp_(\\d+).Rlist", replacement = "\\1", perl = TRUE) %>% type.convert(as.is = TRUE))] %>% .[[2]]
# a2 <- list_recon_gtf_sectored %>% .[setdiff(1:length(list_junction_table_sectored), list.files(paste(tempdir, sep = ""), pattern = paste(output_name, "_list_3FT_result_temp_.*.Rlist", sep = "")) %>% gsub(pattern = ".*_temp_(\\d+).Rlist", replacement = "\\1", perl = TRUE) %>% type.convert(as.is = TRUE))] %>% .[[2]]
# a3 <- purrr::map2(.x = list_island_intervals, .y = vector_ref_genome_fasta_path, .f = ~rep(.y, times = nrow(.x))) %>% flatten %>% .[setdiff(1:length(list_junction_table_sectored), list.files(paste(tempdir, sep = ""), pattern = paste(output_name, "_list_3FT_result_temp_.*.Rlist", sep = "")) %>% gsub(pattern = ".*_temp_(\\d+).Rlist", replacement = "\\1", perl = TRUE) %>% type.convert(as.is = TRUE))] %>% .[[2]]
# a4 <- list_island_intervals %>% dplyr::bind_rows() %>% purrr::array_tree() %>% .[setdiff(1:length(list_junction_table_sectored), list.files(paste(tempdir, sep = ""), pattern = paste(output_name, "_list_3FT_result_temp_.*.Rlist", sep = "")) %>% gsub(pattern = ".*_temp_(\\d+).Rlist", replacement = "\\1", perl = TRUE) %>% type.convert(as.is = TRUE))] %>% .[[2]]
# a5 <- setdiff(1:length(list_junction_table_sectored), list.files(paste(tempdir, sep = ""), pattern = paste(output_name, "_list_3FT_result_temp_.*.Rlist", sep = "")) %>% gsub(pattern = ".*_temp_(\\d+).Rlist", replacement = "\\1", perl = TRUE) %>% type.convert(as.is = TRUE)) %>% .[[2]]

# DIAGNOSTICS ###

# i <- 57
# 
# a1 <- list_junction_table_sectored[[i]]
# a2 <- list_recon_gtf_sectored[[i]]
# a3 <- purrr::map2(.x = list_island_intervals, .y = vector_ref_genome_fasta_path, .f = ~rep(.y, times = nrow(.x))) %>% flatten %>% .[[i]]
# a4 <- list_island_intervals %>% dplyr::bind_rows() %>% purrr::array_tree() %>% .[[i]]
# a5 <- (1:length(list_junction_table_sectored)) %>% .[[i]]
# 
# a3
# 
# reference_genome_fasta_chr_temp <- seqinr::read.fasta(file = a3, forceDNAtolower = FALSE)
# 
# nrow(a1)
# 
# test <- furrr::future_pmap(
#   .l = list(
#     "b1" = a1 %>% purrr::array_tree(),
#     "b2" = 1:length(a1 %>% purrr::array_tree())),
#   .f = function(b1, b2) {
# 
#     extract_junction.flanking.exons(query_chr = b1$chr %>% type.convert(as.is = TRUE),
#                                     query_start = b1$start %>% type.convert(as.is = TRUE),
#                                     query_end = b1$end %>% type.convert(as.is = TRUE),
#                                     query_strand = b1$strand %>% type.convert(as.is = TRUE),
#                                     tibble_gtf_table = a2,
#                                     tolerance_left = 1,
#                                     tolerance_right = 1,
#                                     tolerance_inside = 1,
#                                     tolerance_outside = 0,
#                                     match_consecutive = TRUE,
#                                     return_type = "exon") %>% return
# 
#   }, .progress = TRUE)
# 
# purrr::map(.x = test, .f = ~length(.x)) %>% unlist %>% min
# purrr::map(.x = test, .f = ~length(.x)) %>% unlist %>% max
# purrr::map(.x = test, .f = ~length(.x)) %>% unlist %>% mean
# 
# purrr::map(.x = test %>% purrr::discard(.p = ~length(.x) == 0), .f = ~(.x %>% purrr::flatten() %>% data.table::rbindlist() %>% nrow)) %>% unlist %>% sum()
# 
# test2 <- purrr::map(.x = test %>% purrr::discard(.p = ~length(.x) == 0), .f = ~(.x %>% purrr::flatten() %>% data.table::rbindlist() %>% nrow))
# 
# min(test2 %>% unlist)
# max(test2 %>% unlist)
# mean(test2 %>% unlist)
# 
# test3 <- purrr::map(.x = test %>% purrr::discard(.p = ~length(.x) == 0), .f = ~(.x %>% purrr::flatten() %>% data.table::rbindlist() %>% nrow)/length(.x))
# 
# min(test3 %>% unlist)
# max(test3 %>% unlist)
# mean(test3 %>% unlist)

#################

list_3FT_result <- round_robin_pmap_callr(
  .l = list(
    "a1" = list_junction_table_sectored,
    "a2" = list_recon_gtf_sectored,
    "a3" = purrr::map2(.x = list_island_intervals, .y = vector_ref_genome_fasta_path, .f = ~rep(.y, times = nrow(.x))) %>% flatten,
    "a4" = list_island_intervals %>% dplyr::bind_rows() %>% purrr::array_tree(),
    "a5" = 1:length(list_junction_table_sectored)
  ),
  .num_workers = ncores_level_1,
  .env_flag = "user",
  .re_export = FALSE,
  .temp_path = paste(tempdir, output_name, "_list_3FT_result_temp.RData", sep = ""),
  .temp_dir = tempdir,
  .objects = ls() %>% .[! . %in% c("list_recon_gtf_sectored", "list_recon_gtf_sectored0", "list_recon_gtf_subset_by_chr", "tibble_recon_gtf")],
  .status_messages_dir = paste(tempdir, sep = ""),
  .job_name = paste(output_name, "_list_3FT_result", sep = ""),
  .result_mode = "unordered",
  .f = function(a1, a2, a3, a4, a5) {
    
    # CALLR ###
    library(seqinr)
    library(tidyverse)
    library(furrr)
    library(rtracklayer)
    library(data.table)
    library(optparse)
    library(regioneR)
    
    library(tictoc)
    # start counting execution time of the whole script
    tictoc::tic("Overall execution time")
    
    options(future.globals.maxSize = 30000000000, future.fork.enable = TRUE)
    
    L2_nworkers <- min(c(ncores_level_2, floor(log(base = 8, nrow(a1))) ))
    
    print(paste("L2: now using number of workers:", L2_nworkers))
    
    # if (L2_nworkers <= 1) {
    #   plan(list(tweak(strategy = future::sequential),
    #             tweak(multicore, workers = 1 )))
    # } else {
    #   plan(list(
    #     tweak(multicore, workers = L2_nworkers),
    #     tweak(multicore, workers = 1 )
    #   ) )
    # }
    
    ###########
    
    # DEBUG ###
    # 896
    # 4777
    # a1 <- list_junction_table_sectored[[57]]
    # a2 <- list_recon_gtf_sectored[[57]]
    # a3 <- purrr::map2(.x = list_island_intervals, .y = vector_ref_genome_fasta_path, .f = ~rep(.y, times = nrow(.x))) %>% flatten %>% .[[57]]
    # a4 <- list_island_intervals %>% dplyr::bind_rows() %>% purrr::array_tree() %>% .[[57]]
    # a5 <- (1:length(list_junction_table_sectored)) %>% .[[57]]
    ###########
    
    # Strategy: match junctions to transcripts with directly flanking exons
    # add artificial entry alongside the parent transcript entries indicating the junction
    # later, we use the junction coords to determine the start/end coords according to the specified window using the transcript topology.
    # cat("get junction-flanking exon matches from the GTF\n")
    
    # cat("temporary allocation to ref genome fasta list\n")
    reference_genome_fasta_chr_temp <- seqinr::read.fasta(file = a3, forceDNAtolower = FALSE)
    
    list_3FT_result_temp <- purrr::pmap(
      .l = list(
        "b1" = a1 %>% purrr::array_tree(),
        "b2" = 1:length(a1 %>% purrr::array_tree())),
      .f = function(b1, b2) {
        
        # DEBUG ###
        # b1 <- a1 %>% purrr::array_tree() %>% .[[31]]
        ###########
        
        cat(b2, "\n")
        
        matching_GTF_entries <- extract_junction.flanking.exons(query_chr = b1$chr %>% type.convert(as.is = TRUE),
                                                                query_start = b1$start %>% type.convert(as.is = TRUE),
                                                                query_end = b1$end %>% type.convert(as.is = TRUE),
                                                                query_strand = b1$strand %>% type.convert(as.is = TRUE),
                                                                tibble_gtf_table = a2, 
                                                                tolerance_left = 1, 
                                                                tolerance_right = 1, 
                                                                tolerance_inside = 1, 
                                                                tolerance_outside = 0, 
                                                                match_consecutive = TRUE, 
                                                                return_type = "exon")
        
        # calculate the number of cores we should be using
        effective_rows <- matching_GTF_entries %>% purrr::flatten() %>% data.table::rbindlist() %>% nrow
        
        L3_nworkers <- min(c(ncores_level_3, floor((1.01^(effective_rows/64))^(1/8)) ))
        
        print(paste("L3: now using number of workers:", L3_nworkers))
        
        if (L3_nworkers <= 1) {
          plan(list(tweak(strategy = future::sequential)))
        } else {
          plan(list(tweak(strategy = future::multicore, workers = L3_nworkers)))
        }
        
        matching_GTF_entries_with_artificial_entry <- furrr::future_map(.x = matching_GTF_entries, .f = function(c1) {
          
          # DEBUG ###
          # c1 <- matching_GTF_entries[[1]]
          ###########
          
          # splice in the artificial overlapping exon element using the flanking exons.
          # this entry describes the matched junction in the GTF, which is practically a magnetisation.
          # it will be a single GTF row, with median exon number, spanning the intron junction of the matched transcript.
          list_matched_GTF_entries_with_junction_specification <- purrr::splice(c1,
                                                                                "junction_specifications" = c1$matched_flanking_exons %>% .[1, ] %>% dplyr::select(., -start, -end, -width, -exon_number) %>% add_column("start" = (c1$matched_flanking_exons %>% .[1, "end"] %>% paste %>% as.numeric + 1), "end" = (c1$matched_flanking_exons %>% .[2, "start"] %>% paste %>% as.numeric - 1), "exon_number" = mean(c1$matched_flanking_exons %>% .$exon_number %>% as.numeric)) %>% add_column("width" = .$end %>% as.numeric - .$start %>% as.numeric + 1))
          
          # if intronic, then splice in the intronic region into the parent transcript.
          if (grepl(x = b1$splicemode, pattern = intron_retention_string) == TRUE) {
            
            list_matched_GTF_entries_with_junction_specification$parent_transcript <- dplyr::bind_rows(list_matched_GTF_entries_with_junction_specification$parent_transcript, 
                                                                                                       list_matched_GTF_entries_with_junction_specification$junction_specifications) %>% dplyr::arrange(exon_number)
            
          }
          
          return(list_matched_GTF_entries_with_junction_specification)
          
        }, .progress = TRUE ) # L3
        
        final_identifier <- if (b1$custom_identifier %>% is.na != TRUE) {b1$custom_identifier
        } else {
          paste(source_tag, "_junction_", b1$chr, ":", b1$start %>% type.convert, "-", b1$end%>% type.convert, 
                if ((b1$strand == "+" | b1$strand == "-") & b1$strand %>% is.na != TRUE) {
                  paste(":", b1$strand, sep = "")
                } else {
                  ""
                }, sep = "")
        }
        
        # create fasta header
        fasta_header <- paste(source_tag, 
                              "|", 
                              final_identifier, 
                              "|", 
                              matching_GTF_entries %>% names %>% paste(collapse = ","), 
                              " OS=",
                              b1$organism, 
                              " GN=",
                              b1$gene_name, sep = "")
        
        # update main list ###
        b1 <- purrr::splice(
          b1 %>% flatten,
          "matching_GTF_entries" = matching_GTF_entries_with_artificial_entry %>% list,
          "final_identifier" = final_identifier %>% list,
          "fasta_header" = fasta_header %>% list
        )
        
        # extract the magnetised junction start and end coords.
        result <- list("3FT_info" = furrr::future_map(.x = b1$matching_GTF_entries, .f = ~list(
          "matched_junction_chr" = .x$junction_specifications$seqnames %>% paste,
          "matched_junction_start" = .x$junction_specifications$start %>% paste,
          "matched_junction_end" = .x$junction_specifications$end %>% paste,
          "matched_junction_strand" = .x$junction_specifications$strand %>% paste,
          # generate vector of all nucleotide coors from $start to $end
          "all_parent_transcript_coords" = purrr::map2(.x = .x[["parent_transcript"]]$start, .y = .x[["parent_transcript"]]$end, .f = ~.x:.y) %>% unlist %>% sort) %>%
            # add in the TRANSCRIPT-RELATIVE POSITIONS of the JUNCTION ACCORDING TO THE SPECIFIED WINDOW
            purrr::splice(., 
                          "translation_window_start_transcript.relative" = if (.$matched_junction_strand == "+") {
                            max(1, which(.$all_parent_transcript_coords == (.$matched_junction_start %>% as.numeric - 1)) - upstream_window_size + 1) 
                          } else if (.$matched_junction_strand == "-") {
                            max(1, which(.$all_parent_transcript_coords %>% rev == (.$matched_junction_end %>% as.numeric + 1)) - upstream_window_size + 1) 
                          }, 
                          "translation_window_end_transcript.relative" = if (.$matched_junction_strand == "+") {
                            min(length(.$all_parent_transcript_coords), which(.$all_parent_transcript_coords == (.$matched_junction_end %>% as.numeric + 1)) + downstream_window_size - 1) 
                          } else if (.$matched_junction_strand == "-") {
                            min(length(.$all_parent_transcript_coords), which(.$all_parent_transcript_coords %>% rev == (.$matched_junction_start %>% as.numeric - 1)) + downstream_window_size - 1) 
                          },
                          "last_nt_before_splice_junction_transcript_relative" = if (.$matched_junction_strand == "+") {
                            which(.$all_parent_transcript_coords == (.$matched_junction_start %>% as.numeric - 1))
                          } else if (.$matched_junction_strand == "-") {
                            which(.$all_parent_transcript_coords %>% rev == (.$matched_junction_end %>% as.numeric + 1))
                          },
                          "first_nt_after_splice_junction_transcript_relative" = if (.$matched_junction_strand == "+") {
                            which(.$all_parent_transcript_coords == (.$matched_junction_end %>% as.numeric + 1))
                          } else if (.$matched_junction_strand == "-") {
                            which(.$all_parent_transcript_coords %>% rev == (.$matched_junction_start %>% as.numeric - 1)) 
                          },
                          # add in all the nucleotide coords of the PARENT transcript
                          "parent_transcript_forward_nucleotides" = reference_genome_fasta_chr_temp[[b1$chr %>% paste]][.$all_parent_transcript_coords])))
        
        # update L2 list
        b1 <- splice(
          b1,
          result
        )
        
        updated_3FT_info <- furrr::future_imap(
          .x = b1$`3FT_info`, 
          .f = function(c1, c2) {
            
            # DEBUG ###
            # c1 <- b1$`3FT_info`$MSTRG.241.10
            ###########
            
            # cat("now processing entry number", c2, "/", length(list_matched_coords_temp), "\n")
            
            # three frame translation, add translation frame-relative coordinates of window start and end
            L3_result <- purrr::splice(c1, nt.sequence_strand_threeframetranslate(vector_forward_nucleotides = c1$parent_transcript_forward_nucleotides, strand = c1$matched_junction_strand),
                                       "window_start_AA_position_frame_0" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 0)$exon_start_AA_position,
                                       "window_start_AA_position_frame_1" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 1)$exon_start_AA_position,
                                       "window_start_AA_position_frame_2" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 2)$exon_start_AA_position,
                                       "window_end_AA_position_frame_0" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 0)$exon_end_AA_position,
                                       "window_end_AA_position_frame_1" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 1)$exon_end_AA_position,
                                       "window_end_AA_position_frame_2" = calculate_translation_frame_relative_start_end_position(ES = c1$translation_window_start_transcript.relative, EE = c1$translation_window_end_transcript.relative, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 2)$exon_end_AA_position,
                                       "junction_AA_position_frame_0_upstream" = calculate_translation_frame_relative_start_end_position(ES = c1$last_nt_before_splice_junction_transcript_relative + 1, EE = c1$last_nt_before_splice_junction_transcript_relative + 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 0)$exon_start_AA_position,
                                       "junction_AA_position_frame_1_upstream" = calculate_translation_frame_relative_start_end_position(ES = c1$last_nt_before_splice_junction_transcript_relative + 1, EE = c1$last_nt_before_splice_junction_transcript_relative + 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 1)$exon_start_AA_position,
                                       "junction_AA_position_frame_2_upstream" = calculate_translation_frame_relative_start_end_position(ES = c1$last_nt_before_splice_junction_transcript_relative + 1, EE = c1$last_nt_before_splice_junction_transcript_relative + 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 2)$exon_start_AA_position,
                                       "junction_AA_position_frame_0_downstream" = calculate_translation_frame_relative_start_end_position(ES = c1$first_nt_after_splice_junction_transcript_relative - 1, EE = c1$first_nt_after_splice_junction_transcript_relative - 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 0)$exon_start_AA_position,
                                       "junction_AA_position_frame_1_downstream" = calculate_translation_frame_relative_start_end_position(ES = c1$first_nt_after_splice_junction_transcript_relative - 1, EE = c1$first_nt_after_splice_junction_transcript_relative - 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 1)$exon_start_AA_position,
                                       "junction_AA_position_frame_2_downstream" = calculate_translation_frame_relative_start_end_position(ES = c1$first_nt_after_splice_junction_transcript_relative - 1, EE = c1$first_nt_after_splice_junction_transcript_relative - 1, TL = length(c1$all_parent_transcript_coords), strand = "+", frame = 2)$exon_start_AA_position) %>%
              # check for upstream ORF as well as downstream ORF (starting from within the exon) by seeing if you reverse the AA sequence, do you see a methionine always before the first stop codon
              # will enter logical indicating whether the exon has a valid uORF or not in the given translation frame
              purrr::splice(
                # uORF
                "uORF_valid_frame_0" = find_valid_uORF(.[c("translation_frame_0", "window_start_AA_position_frame_0", "window_end_AA_position_frame_0", "junction_AA_position_frame_0_upstream")]),
                "uORF_valid_frame_1" = find_valid_uORF(.[c("translation_frame_1", "window_start_AA_position_frame_1", "window_end_AA_position_frame_1", "junction_AA_position_frame_1_upstream")]),
                "uORF_valid_frame_2" = find_valid_uORF(.[c("translation_frame_2", "window_start_AA_position_frame_2", "window_end_AA_position_frame_2", "junction_AA_position_frame_2_upstream")]),
                # dORF
                "dORF_valid_frame_0" = find_valid_dORF(.[c("translation_frame_0", "window_start_AA_position_frame_0", "window_end_AA_position_frame_0", "junction_AA_position_frame_0_downstream")]),
                "dORF_valid_frame_1" = find_valid_dORF(.[c("translation_frame_1", "window_start_AA_position_frame_1", "window_end_AA_position_frame_1", "junction_AA_position_frame_1_downstream")]),
                "dORF_valid_frame_2" = find_valid_dORF(.[c("translation_frame_2", "window_start_AA_position_frame_2", "window_end_AA_position_frame_2", "junction_AA_position_frame_2_downstream")])
              ) %>%
              # collapse the forward nucleotide and 3FT sequences into string from a vector
              purrr::modify_at(.x = ., .at = c("parent_transcript_forward_nucleotides", "translation_frame_0", "translation_frame_1", "translation_frame_2"), .f = ~.x %>% paste(collapse = "")) %>% 
              # collapse the parent transcript coords into string from a vector
              purrr::modify_at(.x = ., .at = c("all_parent_transcript_coords"), .f = ~.x %>% paste(collapse = ","))
            
            return(L3_result)
            
          } ) # L3
        
        # update L2 list
        b1$`3FT_info` <- updated_3FT_info
        
        # tibblise and remove duplicates
        if (length(b1) == 0 | length(updated_3FT_info) == 0) {
          return(NULL)
        } else {
          
          # rbind and tibblise
          tibble_3FT_info <- furrr::future_map(
            .x = b1$`3FT_info`,
            .f = ~data.table::as.data.table(.x)
          ) %>% data.table::rbindlist() %>% tibble::as_tibble()
          
          element.indices_frame_info <- grep(x = colnames(tibble_3FT_info), pattern = "frame_\\d")
          element.indices_not_frame_info <- setdiff(1:ncol(tibble_3FT_info), element.indices_frame_info)
          # element indices containing the virtual peptides
          element.indices_virtual_peptides <- grep(x = colnames(tibble_3FT_info), pattern = "^translation_frame_\\d$")
          # element indices of the frame info but not the virtual peptides
          element.indices_not_virtual_peptides <- setdiff(element.indices_frame_info, element.indices_virtual_peptides)
          
          # retrieve all translation frames that have been generated
          vector_translation_frames <- gsub(x = colnames(tibble_3FT_info[, element.indices_virtual_peptides]), pattern = "^translation_frame_(\\d)$", replacement = "\\1")
          
          # split the table by frames
          tibble_3FT_info_split <- purrr::map(
            .x = vector_translation_frames,
            .f = function(c1) {
              
              tibble_frame_info_L3 <- tibble_3FT_info[, element.indices_frame_info] %>%
                dplyr::select(contains(match = paste("frame_", c1, sep = ""))) %>% 
                dplyr::mutate("translation_frame" = c1 %>% type.convert(as.is = TRUE), .before = 1)
              
              colnames(tibble_frame_info_L3) <- gsub(x = colnames(tibble_frame_info_L3), pattern = "_frame_\\d", replacement = "")
              
              colnames(tibble_frame_info_L3)[colnames(tibble_frame_info_L3) == "translation"] <- "parent_transcript_virtual_peptide_sequence"
              
              tibble_result <- dplyr::bind_cols(tibble_3FT_info[, element.indices_not_frame_info], tibble_frame_info_L3)
              
              return(tibble_result)
              
            } ) %>%
            dplyr::bind_rows()
          
          tibble_fully_tibblised_list <- dplyr::bind_cols(
            b1[c("chr", "start", "end", "strand", "gene_name", "fasta_header", "final_identifier", "splicemode")] %>% tibble::as_tibble(),
            tibble_3FT_info_split
          )
          
          if (nrow(tibble_fully_tibblised_list) == 0) {
            
            return(NULL)
            
          } else {
            
            # make single column for uORF and dORF. remove duplicates.
            tibble_fully_tibblised_list <- dplyr::bind_rows(
              tibble_fully_tibblised_list %>% dplyr::select(-uORF_valid) %>% dplyr::rename("virtual_peptide_sequence" = "dORF_valid") %>% tibble::add_column("ORF_type" = "dORF"),
              tibble_fully_tibblised_list %>% dplyr::select(-dORF_valid) %>% dplyr::rename("virtual_peptide_sequence" = "uORF_valid") %>% tibble::add_column("ORF_type" = "uORF")) %>%
              dplyr::distinct(fasta_header, virtual_peptide_sequence, .keep_all = TRUE)
            
            # remove entries with no valid translations.
            tibble_fully_tibblised_list <- tibble_fully_tibblised_list[tibble_fully_tibblised_list$virtual_peptide_sequence != "NONE_VALID" & !is.na(tibble_fully_tibblised_list$virtual_peptide_sequence), ]
            
            return(tibble_fully_tibblised_list)
            
          }
          
        }
        
      } ) # L2
    
    tibble_3FT_result_temp <- list_3FT_result_temp %>%
      purrr::discard(.p = ~length(.x) == 0) %>%
      data.table::rbindlist() %>% 
      tibble::as_tibble()
    
    # saveRDS(tibble_3FT_result_temp, file = paste(tempdir, output_name, "_list_3FT_result_temp_", a5, ".Rlist", sep = ""), compress = TRUE)
    
    return(tibble_3FT_result_temp)
    
  } )

cat("cleanup\n")

# rbind and tibblise
tibble_three_frame_translate_result1 <- list_3FT_result %>%
  data.table::rbindlist() %>%
  tibble::as_tibble()
  
# remove all rows with duplicated u/dORF_valid columns from the table
tibble_three_frame_translate_result2 <- tibble_three_frame_translate_result1[!(duplicated(tibble_three_frame_translate_result1$virtual_peptide_sequence)) & !is.na(tibble_three_frame_translate_result1$virtual_peptide_sequence), ]

plan(list(tweak(multicore, workers = ncores_level_1),
          tweak(multicore, workers = 1)))

vector_virtual_peptide_sequence <- tibble_three_frame_translate_result2$virtual_peptide_sequence

vector_substring_or_not <- round_robin_pmap_callr(
  .l = list(
    "a1" = purrr::map(.x = parallel::splitIndices(nx = length(vector_virtual_peptide_sequence), ncl = 16), .f = ~vector_virtual_peptide_sequence %>% .[.x]),
    "a2" = parallel::splitIndices(nx = length(vector_virtual_peptide_sequence), ncl = 16),
    "a3" = 1:length(purrr::map(.x = parallel::splitIndices(nx = length(vector_virtual_peptide_sequence), ncl = 16), .f = ~vector_virtual_peptide_sequence %>% .[.x]))
  ),
  .num_workers = ncores_level_1,
  .env_flag = "user",
  .re_export = TRUE,
  .temp_path = paste(tempdir, output_name, "_vector_substring_or_not_temp.RData", sep = ""),
  .temp_dir = tempdir,
  .objects = ls() %>% .[! . %in% c("list_recon_gtf_sectored", "list_recon_gtf_sectored0", "list_recon_gtf_subset_by_chr", "list_3FT_result", "tibble_three_frame_translate_result1", "tibble_three_frame_translate_result2", "tibble_recon_gtf", "tibble_junction_table", "list_junction_table_by_chr", "list_junction_table_sectored", "list_junction_table_sectored0")],
  .status_messages_dir = paste(tempdir, sep = ""),
  .job_name = paste(output_name, "_vector_substring_or_not", sep = ""),
  .result_mode = "ordered",
  .f = function(a1, a2, a3, a4, a5) {
    
    # cat(a2, "\n")
    
    # CALLR ###
    library(seqinr)
    library(tidyverse)
    library(furrr)
    library(rtracklayer)
    library(data.table)
    library(optparse)
    library(regioneR)
    
    library(tictoc)
    # start counting execution time of the whole script
    tictoc::tic("Overall execution time")
    
    options(future.globals.maxSize = 30000000000, future.fork.enable = TRUE)
    
    plan(list(tweak(multicore, workers = ncores_level_2)))
    ###########
    
    # DEBUG ###
    # a1 <- vector_virtual_peptide_sequence %>% .[[74139]]
    # a2 <- 1:nrow(tibble_summarised_results3) %>% .[[74139]]
    ###########
    
    purrr::map2(
      .x = a1,
      .y = a2,
      .f = ~grepl(x = vector_virtual_peptide_sequence[-a2], pattern = .x, perl = TRUE) %>% any %>% return
    ) %>% unlist %>% return
    
  } ) %>% unlist

tibble_three_frame_translate_result3 <- tibble_three_frame_translate_result2 %>% 
  # add column to indicate if the virtual peptide per row is a substring of another row
  tibble::add_column("substring_or_not" = vector_substring_or_not)

# filter out substrings
tibble_three_frame_translate_result4 <- tibble_three_frame_translate_result3 %>% dplyr::filter(substring_or_not == FALSE)

# fix up columns that are ORF side specific
tibble_three_frame_translate_result5 <- tibble_three_frame_translate_result4 %>% 
  dplyr::mutate("junction_AA_position" = purrr::pmap(
    .l = list(
      "a1" = `junction_AA_position_upstream`, 
      "a2" = `junction_AA_position_downstream`, 
      "a3" = `ORF_type`), 
    .f = function(a1, a2, a3) {
      if (a3 == "uORF") {
        return(a1)
      } else if (a3 == "dORF") {
        return(a2)
      }
    }
  ) %>% unlist )

# tally up the number of valid frames we ended up with
tibble_junctions_frame_tally <- tibble_three_frame_translate_result5 %>% dplyr::distinct(translation_frame, fasta_header) %>% dplyr::group_by(fasta_header) %>% dplyr::summarise("tally" = n())

cat("\nnumber of junctions input: ", tibble_junction_table %>% dplyr::distinct(chr, start, end, strand) %>% nrow, "\n")
cat("\nnumber of junctions translated: ", tibble_three_frame_translate_result5$final_identifier %>% unique %>% length, "\n")
cat("\naverage number of translation frames for UNIQUE junction sequences: ", mean(tibble_junctions_frame_tally$tally), "\n")

# WE WRITE A TIBBLE CONTAINING THE GENOME COORD-PEPTIDE MAPPING
# write a table
data.table::fwrite(x = tibble_three_frame_translate_result5, file = paste(output_dir, "/", output_name, "_3FT.summary.info.txt", sep = ""), sep = "\t", col.names = TRUE, row.names = FALSE, quote = FALSE)

# FINALLY! WE WRITE THE FASTA!
write.fasta(sequences = tibble_three_frame_translate_result5$virtual_peptide_sequence %>% array_tree %>% flatten, names = tibble_three_frame_translate_result5$fasta_header, file.out = paste(output_dir, "/", output_name, ".fasta", sep = ""), open = "w", nbchar = 40, as.string = TRUE)

# write final junction table as .bed file
cat(paste("track name=\"Alternative junctions\" description=\"", output_name, "\" graphType=junctions\n", sep = ""), file = paste(output_dir, "/", output_name, "_junctions.bed", sep = ""))

junc_bed_table <- tibble_three_frame_translate_result5[, c("chr", "start", "end", "final_identifier", "strand")] %>% setNames(c("chr", "start", "end", "name", "strand")) %>% add_column(., "score" = 1000, .after = "name") %>% type_convert

write.table(junc_bed_table, file = paste(output_dir, "/", output_name, "_junctions.bed", sep = ""), sep = "\t", col.names = FALSE, row.names = FALSE, quote = FALSE, append = TRUE)

if (save_workspace_when_done == "YES" | save_workspace_when_done == "DEBUG") {
  save.image(file = paste(output_dir, "/", output_name, "_workspace.RData", sep = ""))
}

if (save_workspace_when_done != "DEBUG") {
  unlink(paste(output_dir, "temp/", sep = ""), recursive = TRUE)
}

# finish counting
tictoc::toc()

q()

